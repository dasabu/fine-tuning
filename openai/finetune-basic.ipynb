{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d79b2cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import tiktoken # for token counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "483bc822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b31546a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd8938e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae956a5",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b65406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_jsonl(input_file, output_file):\n",
    "    \"\"\"Converts a JSON file to a JSONL file.\"\"\"\n",
    "    # Open JSON file\n",
    "    f = open(input_file)\n",
    "\n",
    "    # Returns JSON object as a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Produce JSONL from JSON\n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        for entry in data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fe8521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_file_format(dataset):\n",
    "    \"\"\"Checks the format of a dataset.\"\"\"\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in dataset:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "\n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "\n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "\n",
    "            if any(\n",
    "                k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message\n",
    "            ):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "\n",
    "            if message.get(\"role\", None) not in (\n",
    "                \"system\",\n",
    "                \"user\",\n",
    "                \"assistant\",\n",
    "                \"function\",\n",
    "            ):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "\n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "\n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "\n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(\"Found errors:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"No errors found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63d3e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49b8fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to JSONL\n",
    "json_to_jsonl(\"teacrafter.json\", \"output.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd76f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (https://cookbook.openai.com/examples/chat_finetuning_data_prep)\n",
    "data_path = \"output.jsonl\"\n",
    "\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42aca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 18\n",
      "First example:\n",
      "{'role': 'system', 'content': 'This is a customer support chatbot designed to help with inquiries for TeaCrafters, an artisan tea subscription service.'}\n",
      "{'role': 'user', 'content': 'How do I change my tea preferences for the next shipment?'}\n",
      "{'role': 'assistant', 'content': \"You can update your tea preferences by logging into your account and visiting the 'Subscription Settings' page. Changes must be made at least 7 days before your next shipment.\"}\n"
     ]
    }
   ],
   "source": [
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93c2c409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found!\n"
     ]
    }
   ],
   "source": [
    "# Format validation\n",
    "check_file_format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf3f1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~1437 tokens that will be charged for during training\n",
      "Train for 5 epochs and be charged for ~7185 tokens\n",
      "Estimated cost: 0.021555\n"
     ]
    }
   ],
   "source": [
    "# Cost estimations\n",
    "conversation_length = [] # Get the length of the conversation\n",
    "\n",
    "for msg in dataset:\n",
    "    messages = msg[\"messages\"]\n",
    "    conversation_length.append(num_tokens_from_messages(messages))\n",
    "\n",
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "TARGET_EPOCHS = 5\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(\n",
    "    min(MAX_TOKENS_PER_EXAMPLE, length) for length in conversation_length\n",
    ")\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"Train for {n_epochs} epochs and be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
    "\n",
    "num_tokens = n_epochs * n_billing_tokens_in_dataset\n",
    "\n",
    "# Pricing: https://platform.openai.com/docs/pricing\n",
    "# gpt-4o-mini-2024-07-18: $3.00 / 1M tokens\n",
    "cost = (num_tokens / 1e6) * 3\n",
    "print(f\"Estimated cost: {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e54a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-9JF9pUDLi453Tqa1tkd8hJ\n"
     ]
    }
   ],
   "source": [
    "# Upload file once all validations are successful!\n",
    "training_file = client.files.create(\n",
    "    file=open(\"output.jsonl\", \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "print(training_file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0b11b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the fine-tuning job (may take some time to complete, based on model and dataset)\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": n_epochs,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e9e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-GAPULfJ44qMeS1ZpXfNXTcee\n"
     ]
    }
   ],
   "source": [
    "print(job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb9070a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: validating_files\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: running\n",
      "Wait for 30 seconds before checking again\n",
      "Current status: succeeded\n",
      "Fine-tuned-model: ft:gpt-4o-mini-2024-07-18:personal::BokouGwm\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "# Status field can contain: running || succeeded || failed, etc.\n",
    "fine_tuned_model = None\n",
    "while not fine_tuned_model:\n",
    "    state = client.fine_tuning.jobs.retrieve(job.id)\n",
    "    print(\"Current status:\", state.status)\n",
    "    # Done: get fine-tuned model\n",
    "    if state.status == \"succeeded\":\n",
    "        fine_tuned_model = state.fine_tuned_model\n",
    "        print(\"Fine-tuned-model:\", fine_tuned_model)\n",
    "    # Wait for 30 seconds before checking again\n",
    "    else:\n",
    "        print(\"Wait for 30 seconds before checking again\")\n",
    "        time.sleep(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3211a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-4o-mini-2024-07-18:personal::BokouGwm\n"
     ]
    }
   ],
   "source": [
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ae6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned response:\n",
      "To cancel your subscription, log into your account and visit the 'Subscription Settings' page. Click on 'Cancel Subscription' and follow the prompts. Please note that cancellations must be made at least 24 hours before your next billing cycle.\n"
     ]
    }
   ],
   "source": [
    "# Get response from fine-tuned model\n",
    "response = client.chat.completions.create(\n",
    "    model=fine_tuned_model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I cancel my subscription?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"Fine-tuned response:\")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Note: Not so good, try 10-15 epochs insteal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffa4a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal response:\n",
      "To cancel your subscription, you'll typically need to follow these general steps, though the specific process may vary depending on the service:\n",
      "\n",
      "1. **Log into Your Account**: Go to the website or app of the service you're subscribed to and log into your account.\n",
      "\n",
      "2. **Navigate to Account Settings**: Look for a section labeled \"Account,\" \"Settings,\" or \"Subscription Management.\"\n",
      "\n",
      "3. **Find Subscription Information**: Within the account settings, find the area that contains details about your subscription or billing.\n",
      "\n",
      "4. **Select Cancel Subscription**: Look for an option to cancel or manage your subscription. This might be labeled as \"Cancel Subscription,\" \"End Membership,\" or similar.\n",
      "\n",
      "5. **Follow the Prompts**: The service will likely guide you through the cancellation process. You may need to confirm your decision or provide a reason for canceling.\n",
      "\n",
      "6. **Check for Confirmation**: After canceling, ensure that you receive a confirmation (via email or on-screen) that your subscription has been successfully canceled.\n",
      "\n",
      "If you're unable to find the cancellation option or need specific instructions for a particular service, it might be helpful to consult the help or support section on their website. Alternatively, you can contact their customer support for assistance.\n"
     ]
    }
   ],
   "source": [
    "# Get response from normal model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"This is a customer support chatbot designed to help with common inquiries.\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I cancel my subscription?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\"Normal response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a8283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
